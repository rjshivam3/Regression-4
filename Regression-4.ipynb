{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149d8445-ac34-4e12-a002-9233e24fdf6a",
   "metadata": {},
   "source": [
    "## Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40018d00-25d6-4200-b908-a8ec288d9ec9",
   "metadata": {},
   "source": [
    "Lasso Regression, or Least Absolute Shrinkage and Selection Operator, is a type of linear regression that includes a regularization term. This term adds a penalty equal to the absolute value of the magnitude of the coefficients, encouraging sparsity in the model.\n",
    "\n",
    "Lasso Regression differs from other regression techniques like ordinary least squares (OLS) and Ridge Regression in that it can shrink some coefficients to exactly zero. This feature makes it particularly useful for feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538bd4e5-f6cb-420f-a5a5-334130998b4d",
   "metadata": {},
   "source": [
    "## Q2. What is the main advantage of using Lasso Regression in feature selection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d381c37-3ad1-4828-9489-bd461a3d17c8",
   "metadata": {},
   "source": [
    "The main advantage of using Lasso Regression in feature selection is its ability to shrink some coefficients to exactly zero. This means it can effectively select a subset of the most important features, simplifying the model and improving interpretability without the need for additional feature selection methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4134c7de-6fb3-40c2-9cbe-071a59f2aa3d",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the coefficients of a Lasso Regression model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d46f5e-6e8e-4a87-8d62-6431cfb13142",
   "metadata": {},
   "source": [
    "The coefficients of a Lasso Regression model represent the change in the dependent variable for a one-unit change in the corresponding independent variable, holding other variables constant. Coefficients that are exactly zero indicate that the corresponding features are not important predictors in the model. Non-zero coefficients indicate the importance of those features, with larger coefficients suggesting a stronger influence on the dependent variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb41cb8-084a-497a-9657-3326cf5c5c9d",
   "metadata": {},
   "source": [
    "## Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189bfaf-2d74-4450-973e-2f5b0632caea",
   "metadata": {},
   "source": [
    "The primary tuning parameter in Lasso Regression is the regularization parameter (lambda). It controls the strength of the penalty applied to the coefficients:\n",
    "\n",
    "- A higher lambda value increases the penalty, leading to more coefficients being shrunk to zero. This results in a sparser model.\n",
    "- A lower lambda value reduces the penalty, allowing more coefficients to remain non-zero, which can lead to overfitting if the model becomes too complex.\n",
    "\n",
    "Selecting the appropriate lambda value balances the trade-off between model complexity and overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e5fc7-c71c-488f-ab35-96f247af33b9",
   "metadata": {},
   "source": [
    "## Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d08ee-eaa5-4032-802e-71ad878a0036",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can be used for non-linear regression problems by incorporating polynomial features or interaction terms. By transforming the original features into a higher-dimensional space, Lasso Regression can model non-linear relationships while still benefiting from regularization and feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6900e0e-79e6-4fa5-89d7-6c3ef6e45539",
   "metadata": {},
   "source": [
    "## Q6. What is the difference between Ridge Regression and Lasso Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee72dfc9-b02d-472e-a304-cf7be0641848",
   "metadata": {},
   "source": [
    "The main difference between Ridge Regression and Lasso Regression lies in the type of regularization penalty applied:\n",
    "\n",
    "- Ridge Regression uses L2 regularization, adding a penalty equal to the square of the magnitude of coefficients. It shrinks coefficients but does not set any to zero.\n",
    "- Lasso Regression uses L1 regularization, adding a penalty equal to the absolute value of the magnitude of coefficients. It can shrink some coefficients to exactly zero, performing feature selection.\n",
    "\n",
    "Ridge Regression is preferred when all features are believed to be relevant, while Lasso Regression is useful for sparse models and feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44937756-671a-486f-bc60-f9516f99f7f9",
   "metadata": {},
   "source": [
    "## Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c03183-0e3e-4aed-b3bb-85857ff68af2",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can handle multicollinearity in the input features. It does so by shrinking some coefficients to zero, effectively removing the less important features from the model. This reduces the impact of multicollinearity by selecting the most relevant features and ignoring the redundant ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a1b326-4f63-4d35-91fd-78b1054f02cd",
   "metadata": {},
   "source": [
    "## Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec1586-d64c-4a96-8821-aa6b4a74004c",
   "metadata": {},
   "source": [
    "The optimal value of the regularization parameter (lambda) in Lasso Regression is typically chosen using cross-validation. The process involves:\n",
    "\n",
    "1. Splitting the data into training and validation sets.\n",
    "2. Fitting the Lasso Regression model on the training set with different values of lambda.\n",
    "3. Evaluating the model performance on the validation set for each lambda.\n",
    "4. Selecting the lambda that provides the best performance on the validation set, usually in terms of minimizing the mean squared error (MSE).\n",
    "\n",
    "Tools such as GridSearchCV in scikit-learn can automate this process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0b9b0-3c53-43a3-a9b9-1ec3468d38bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
